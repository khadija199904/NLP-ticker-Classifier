import os
import sys
import chromadb
import pandas as pd
import joblib
import time
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from embedding_service import get_chroma_client

# Ajout du chemin parent pour l'import de config
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from config import (
    CHROMA_HOST, 
    CHROMA_PORT, 
    COLLECTION_NAME, 
    MODEL_SAVE_PATH
)

def load_data_from_chroma():
    """
    R√©cup√®re les embeddings et les labels directement depuis ChromaDB.
    √âvite de recalculer les embeddings √† chaque entra√Ænement.
    """
    try:
        print("üîÑ Chargement des donn√©es...")
        client = get_chroma_client()
        collection = client.get_collection(name=COLLECTION_NAME)
    
        total = collection.count()
        X, y = [], []
        batch_size = 5000  # On t√©l√©charge 5000 par 5000

        for i in range(0, total, batch_size):
        # R√©cup√©ration simplifi√©e
           res = collection.get(include=["embeddings", "metadatas"], limit=batch_size, offset=i)
        
           X.extend(res['embeddings'])
           y.extend([m['type'] for m in res['metadatas']])
           print(f"‚úÖ {len(X)} / {total} r√©cup√©r√©s")

        return X, y
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es : {e}")
        return None, None

def train_and_evaluate():
    
    X, y = load_data_from_chroma()
    
    if X is None or len(X) == 0:
        print("üõë Impossible de continuer : Aucune donn√©e trouv√©e dans ChromaDB.")
        return

    # 2. S√©paration des donn√©es (80% Train / 20% Test)
    # stratify=y permet de garder la m√™me proportion de classes dans les deux sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.20, random_state=42, stratify=y
    )
    
    print(f"üìä Dataset split : Train={len(X_train)} | Test={len(X_test)}")

    # 3. Entra√Ænement du mod√®le
    # LogisticRegression est excellente pour les embeddings (haute dimension)
    print("üöÄ Entra√Ænement du classifieur (Logistic Regression)...")
    clf = LogisticRegression(
        max_iter=1000, 
        solver='lbfgs',
        C=1.0 # Param√®tre de r√©gularisation
    )
    
    start_train = time.time()
    clf.fit(X_train, y_train)
    train_duration = time.time() - start_train
    print(f"‚úÖ Entra√Ænement termin√© en {train_duration:.2f}s")

    # 4. √âvaluation
    y_pred = clf.predict(X_test)
    
    print("\n" + "="*40)
    print("üìà RAPPORT DE PERFORMANCE")
    print("="*40)
    print(f"Accuracy Score: {accuracy_score(y_test, y_pred):.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    print("="*40)
    
    model_dir = os.path.dirname(MODEL_SAVE_PATH)

    # 2. On cr√©e le dossier s'il n'existe pas
    if model_dir: # Si le chemin contient un dossier
        os.makedirs(model_dir, exist_ok=True)
        print(f"üìÅ Dossier v√©rifi√©/cr√©√© : {model_dir}")

    joblib.dump(clf, MODEL_SAVE_PATH)
    print(f"üíæ Mod√®le sauvegard√© avec succ√®s : {MODEL_SAVE_PATH}")

if __name__ == "__main__":
    train_and_evaluate()